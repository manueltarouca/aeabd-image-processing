SqueezeNet Model training starting now!
Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_357 (Conv2D)             (None, 111, 111, 64) 1792        input_7[0][0]                    
__________________________________________________________________________________________________
activation_363 (Activation)     (None, 111, 111, 64) 0           conv2d_357[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_21 (MaxPooling2D) (None, 55, 55, 64)   0           activation_363[0][0]             
__________________________________________________________________________________________________
conv2d_358 (Conv2D)             (None, 55, 55, 16)   1040        max_pooling2d_21[0][0]           
__________________________________________________________________________________________________
activation_364 (Activation)     (None, 55, 55, 16)   0           conv2d_358[0][0]                 
__________________________________________________________________________________________________
conv2d_359 (Conv2D)             (None, 55, 55, 64)   1088        activation_364[0][0]             
__________________________________________________________________________________________________
conv2d_360 (Conv2D)             (None, 55, 55, 64)   9280        activation_364[0][0]             
__________________________________________________________________________________________________
activation_365 (Activation)     (None, 55, 55, 64)   0           conv2d_359[0][0]                 
__________________________________________________________________________________________________
activation_366 (Activation)     (None, 55, 55, 64)   0           conv2d_360[0][0]                 
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 55, 55, 128)  0           activation_365[0][0]             
                                                                 activation_366[0][0]             
__________________________________________________________________________________________________
conv2d_361 (Conv2D)             (None, 55, 55, 16)   2064        concatenate_30[0][0]             
__________________________________________________________________________________________________
activation_367 (Activation)     (None, 55, 55, 16)   0           conv2d_361[0][0]                 
__________________________________________________________________________________________________
conv2d_362 (Conv2D)             (None, 55, 55, 64)   1088        activation_367[0][0]             
__________________________________________________________________________________________________
conv2d_363 (Conv2D)             (None, 55, 55, 64)   9280        activation_367[0][0]             
__________________________________________________________________________________________________
activation_368 (Activation)     (None, 55, 55, 64)   0           conv2d_362[0][0]                 
__________________________________________________________________________________________________
activation_369 (Activation)     (None, 55, 55, 64)   0           conv2d_363[0][0]                 
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 55, 55, 128)  0           activation_368[0][0]             
                                                                 activation_369[0][0]             
__________________________________________________________________________________________________
max_pooling2d_22 (MaxPooling2D) (None, 27, 27, 128)  0           concatenate_31[0][0]             
__________________________________________________________________________________________________
conv2d_364 (Conv2D)             (None, 27, 27, 32)   4128        max_pooling2d_22[0][0]           
__________________________________________________________________________________________________
activation_370 (Activation)     (None, 27, 27, 32)   0           conv2d_364[0][0]                 
__________________________________________________________________________________________________
conv2d_365 (Conv2D)             (None, 27, 27, 128)  4224        activation_370[0][0]             
__________________________________________________________________________________________________
conv2d_366 (Conv2D)             (None, 27, 27, 128)  36992       activation_370[0][0]             
__________________________________________________________________________________________________
activation_371 (Activation)     (None, 27, 27, 128)  0           conv2d_365[0][0]                 
__________________________________________________________________________________________________
activation_372 (Activation)     (None, 27, 27, 128)  0           conv2d_366[0][0]                 
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 27, 27, 256)  0           activation_371[0][0]             
                                                                 activation_372[0][0]             
__________________________________________________________________________________________________
conv2d_367 (Conv2D)             (None, 27, 27, 32)   8224        concatenate_32[0][0]             
__________________________________________________________________________________________________
activation_373 (Activation)     (None, 27, 27, 32)   0           conv2d_367[0][0]                 
__________________________________________________________________________________________________
conv2d_368 (Conv2D)             (None, 27, 27, 128)  4224        activation_373[0][0]             
__________________________________________________________________________________________________
conv2d_369 (Conv2D)             (None, 27, 27, 128)  36992       activation_373[0][0]             
__________________________________________________________________________________________________
activation_374 (Activation)     (None, 27, 27, 128)  0           conv2d_368[0][0]                 
__________________________________________________________________________________________________
activation_375 (Activation)     (None, 27, 27, 128)  0           conv2d_369[0][0]                 
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 27, 27, 256)  0           activation_374[0][0]             
                                                                 activation_375[0][0]             
__________________________________________________________________________________________________
max_pooling2d_23 (MaxPooling2D) (None, 13, 13, 256)  0           concatenate_33[0][0]             
__________________________________________________________________________________________________
conv2d_370 (Conv2D)             (None, 13, 13, 48)   12336       max_pooling2d_23[0][0]           
__________________________________________________________________________________________________
activation_376 (Activation)     (None, 13, 13, 48)   0           conv2d_370[0][0]                 
__________________________________________________________________________________________________
conv2d_371 (Conv2D)             (None, 13, 13, 192)  9408        activation_376[0][0]             
__________________________________________________________________________________________________
conv2d_372 (Conv2D)             (None, 13, 13, 192)  83136       activation_376[0][0]             
__________________________________________________________________________________________________
activation_377 (Activation)     (None, 13, 13, 192)  0           conv2d_371[0][0]                 
__________________________________________________________________________________________________
activation_378 (Activation)     (None, 13, 13, 192)  0           conv2d_372[0][0]                 
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 13, 13, 384)  0           activation_377[0][0]             
                                                                 activation_378[0][0]             
__________________________________________________________________________________________________
conv2d_373 (Conv2D)             (None, 13, 13, 48)   18480       concatenate_34[0][0]             
__________________________________________________________________________________________________
activation_379 (Activation)     (None, 13, 13, 48)   0           conv2d_373[0][0]                 
__________________________________________________________________________________________________
conv2d_374 (Conv2D)             (None, 13, 13, 192)  9408        activation_379[0][0]             
__________________________________________________________________________________________________
conv2d_375 (Conv2D)             (None, 13, 13, 192)  83136       activation_379[0][0]             
__________________________________________________________________________________________________
activation_380 (Activation)     (None, 13, 13, 192)  0           conv2d_374[0][0]                 
__________________________________________________________________________________________________
activation_381 (Activation)     (None, 13, 13, 192)  0           conv2d_375[0][0]                 
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 13, 13, 384)  0           activation_380[0][0]             
                                                                 activation_381[0][0]             
__________________________________________________________________________________________________
conv2d_376 (Conv2D)             (None, 13, 13, 64)   24640       concatenate_35[0][0]             
__________________________________________________________________________________________________
activation_382 (Activation)     (None, 13, 13, 64)   0           conv2d_376[0][0]                 
__________________________________________________________________________________________________
conv2d_377 (Conv2D)             (None, 13, 13, 256)  16640       activation_382[0][0]             
__________________________________________________________________________________________________
conv2d_378 (Conv2D)             (None, 13, 13, 256)  147712      activation_382[0][0]             
__________________________________________________________________________________________________
activation_383 (Activation)     (None, 13, 13, 256)  0           conv2d_377[0][0]                 
__________________________________________________________________________________________________
activation_384 (Activation)     (None, 13, 13, 256)  0           conv2d_378[0][0]                 
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 13, 13, 512)  0           activation_383[0][0]             
                                                                 activation_384[0][0]             
__________________________________________________________________________________________________
conv2d_379 (Conv2D)             (None, 13, 13, 64)   32832       concatenate_36[0][0]             
__________________________________________________________________________________________________
activation_385 (Activation)     (None, 13, 13, 64)   0           conv2d_379[0][0]                 
__________________________________________________________________________________________________
conv2d_380 (Conv2D)             (None, 13, 13, 256)  16640       activation_385[0][0]             
__________________________________________________________________________________________________
conv2d_381 (Conv2D)             (None, 13, 13, 256)  147712      activation_385[0][0]             
__________________________________________________________________________________________________
activation_386 (Activation)     (None, 13, 13, 256)  0           conv2d_380[0][0]                 
__________________________________________________________________________________________________
activation_387 (Activation)     (None, 13, 13, 256)  0           conv2d_381[0][0]                 
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 13, 13, 512)  0           activation_386[0][0]             
                                                                 activation_387[0][0]             
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 512)  0           concatenate_37[0][0]             
__________________________________________________________________________________________________
last_conv (Conv2D)              (None, 13, 13, 10)   5130        dropout_3[0][0]                  
__________________________________________________________________________________________________
activation_388 (Activation)     (None, 13, 13, 10)   0           last_conv[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_3 (Glo (None, 10)           0           activation_388[0][0]             
__________________________________________________________________________________________________
activation_389 (Activation)     (None, 10)           0           global_average_pooling2d_3[0][0] 
==================================================================================================
Total params: 727,626
Trainable params: 727,626
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
Using Enhanced Data Generation
Found 9000 images belonging to 10 classes.
Found 2000 images belonging to 10 classes.
JSON Mapping for the model classes saved to  /content/drive/My Drive/imageprocessing/idenprof/json/model_class.json
Number of experiments (Epochs) :  25
Epoch 1/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3027 - acc: 0.0977Epoch 1/25
 500/2250 [=====>........................] - ETA: 51s - loss: 2.3026 - acc: 0.1000
Epoch 00001: val_acc improved from -inf to 0.10000, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-001_acc-0.100000.h5
2250/2250 [==============================] - 224s 99ms/step - loss: 2.3027 - acc: 0.0977 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 2/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0978Epoch 1/25
 499/2250 [=====>........................] - ETA: 43s - loss: 2.3026 - acc: 0.1002
Epoch 00002: val_acc did not improve from 0.10000
2250/2250 [==============================] - 195s 87ms/step - loss: 2.3026 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 3/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0996Epoch 1/25
 500/2250 [=====>........................] - ETA: 44s - loss: 2.3026 - acc: 0.1000
Epoch 00003: val_acc did not improve from 0.10000
2250/2250 [==============================] - 194s 86ms/step - loss: 2.3026 - acc: 0.0997 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 4/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0998Epoch 1/25
 500/2250 [=====>........................] - ETA: 41s - loss: 2.3026 - acc: 0.1000
Epoch 00004: val_acc did not improve from 0.10000
2250/2250 [==============================] - 192s 85ms/step - loss: 2.3026 - acc: 0.0999 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 5/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0995Epoch 1/25
 500/2250 [=====>........................] - ETA: 41s - loss: 2.3026 - acc: 0.1000
Epoch 00005: val_acc did not improve from 0.10000
2250/2250 [==============================] - 187s 83ms/step - loss: 2.3026 - acc: 0.0996 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 6/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0999Epoch 1/25
 499/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1002
Epoch 00006: val_acc did not improve from 0.10000
2250/2250 [==============================] - 186s 83ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 7/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 500/2250 [=====>........................] - ETA: 41s - loss: 2.3026 - acc: 0.1000
Epoch 00007: val_acc did not improve from 0.10000
2250/2250 [==============================] - 186s 83ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 8/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 39s - loss: 2.3026 - acc: 0.1002
Epoch 00008: val_acc did not improve from 0.10000
2250/2250 [==============================] - 185s 82ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 9/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 498/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.0994
Epoch 00009: val_acc did not improve from 0.10000
2250/2250 [==============================] - 184s 82ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 10/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 500/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1000
Epoch 00010: val_acc did not improve from 0.10000
2250/2250 [==============================] - 185s 82ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 11/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1002
Epoch 00011: val_acc did not improve from 0.10000
2250/2250 [==============================] - 182s 81ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 12/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 500/2250 [=====>........................] - ETA: 39s - loss: 2.3026 - acc: 0.1000
Epoch 00012: val_acc did not improve from 0.10000
2250/2250 [==============================] - 182s 81ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 13/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 38s - loss: 2.3026 - acc: 0.1002
Epoch 00013: val_acc did not improve from 0.10000
2250/2250 [==============================] - 181s 81ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 14/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0998Epoch 1/25
 498/2250 [=====>........................] - ETA: 42s - loss: 2.3026 - acc: 0.0994
Epoch 00014: val_acc did not improve from 0.10000
2250/2250 [==============================] - 189s 84ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 15/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1002
Epoch 00015: val_acc did not improve from 0.10000
2250/2250 [==============================] - 191s 85ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 16/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 39s - loss: 2.3026 - acc: 0.1002
Epoch 00016: val_acc did not improve from 0.10000
2250/2250 [==============================] - 186s 83ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 17/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1002
Epoch 00017: val_acc did not improve from 0.10000
2250/2250 [==============================] - 189s 84ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 18/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 41s - loss: 2.3026 - acc: 0.1002
Epoch 00018: val_acc did not improve from 0.10000
2250/2250 [==============================] - 189s 84ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 19/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 499/2250 [=====>........................] - ETA: 43s - loss: 2.3026 - acc: 0.1002
Epoch 00019: val_acc did not improve from 0.10000
2250/2250 [==============================] - 192s 85ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 20/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0999Epoch 1/25
 499/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1002
Epoch 00020: val_acc did not improve from 0.10000
2250/2250 [==============================] - 187s 83ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 21/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 500/2250 [=====>........................] - ETA: 45s - loss: 2.3026 - acc: 0.1000
Epoch 00021: val_acc did not improve from 0.10000
2250/2250 [==============================] - 193s 86ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 22/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 500/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.1000
Epoch 00022: val_acc did not improve from 0.10000
2250/2250 [==============================] - 200s 89ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 23/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0999Epoch 1/25
 498/2250 [=====>........................] - ETA: 40s - loss: 2.3026 - acc: 0.0994
Epoch 00023: val_acc did not improve from 0.10000
2250/2250 [==============================] - 188s 83ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 24/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0998Epoch 1/25
 499/2250 [=====>........................] - ETA: 41s - loss: 2.3026 - acc: 0.1002
Epoch 00024: val_acc did not improve from 0.10000
2250/2250 [==============================] - 188s 84ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
Epoch 25/25
2249/2250 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1000Epoch 1/25
 500/2250 [=====>........................] - ETA: 41s - loss: 2.3026 - acc: 0.1000
Epoch 00025: val_acc did not improve from 0.10000
2250/2250 [==============================] - 187s 83ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000
SqueezeNet Model training completed!