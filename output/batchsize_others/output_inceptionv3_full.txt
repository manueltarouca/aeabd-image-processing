InceptionV3 Model training starting now!
Model: "inception_v3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_16 (InputLayer)           [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_1128 (Conv2D)            (None, 111, 111, 32) 864         input_16[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1060 (Batch (None, 111, 111, 32) 96          conv2d_1128[0][0]                
__________________________________________________________________________________________________
activation_1125 (Activation)    (None, 111, 111, 32) 0           batch_normalization_1060[0][0]   
__________________________________________________________________________________________________
conv2d_1129 (Conv2D)            (None, 109, 109, 32) 9216        activation_1125[0][0]            
__________________________________________________________________________________________________
batch_normalization_1061 (Batch (None, 109, 109, 32) 96          conv2d_1129[0][0]                
__________________________________________________________________________________________________
activation_1126 (Activation)    (None, 109, 109, 32) 0           batch_normalization_1061[0][0]   
__________________________________________________________________________________________________
conv2d_1130 (Conv2D)            (None, 109, 109, 64) 18432       activation_1126[0][0]            
__________________________________________________________________________________________________
batch_normalization_1062 (Batch (None, 109, 109, 64) 192         conv2d_1130[0][0]                
__________________________________________________________________________________________________
activation_1127 (Activation)    (None, 109, 109, 64) 0           batch_normalization_1062[0][0]   
__________________________________________________________________________________________________
max_pooling2d_21 (MaxPooling2D) (None, 54, 54, 64)   0           activation_1127[0][0]            
__________________________________________________________________________________________________
conv2d_1131 (Conv2D)            (None, 54, 54, 80)   5120        max_pooling2d_21[0][0]           
__________________________________________________________________________________________________
batch_normalization_1063 (Batch (None, 54, 54, 80)   240         conv2d_1131[0][0]                
__________________________________________________________________________________________________
activation_1128 (Activation)    (None, 54, 54, 80)   0           batch_normalization_1063[0][0]   
__________________________________________________________________________________________________
conv2d_1132 (Conv2D)            (None, 52, 52, 192)  138240      activation_1128[0][0]            
__________________________________________________________________________________________________
batch_normalization_1064 (Batch (None, 52, 52, 192)  576         conv2d_1132[0][0]                
__________________________________________________________________________________________________
activation_1129 (Activation)    (None, 52, 52, 192)  0           batch_normalization_1064[0][0]   
__________________________________________________________________________________________________
max_pooling2d_22 (MaxPooling2D) (None, 25, 25, 192)  0           activation_1129[0][0]            
__________________________________________________________________________________________________
conv2d_1136 (Conv2D)            (None, 25, 25, 64)   12288       max_pooling2d_22[0][0]           
__________________________________________________________________________________________________
batch_normalization_1068 (Batch (None, 25, 25, 64)   192         conv2d_1136[0][0]                
__________________________________________________________________________________________________
activation_1133 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1068[0][0]   
__________________________________________________________________________________________________
conv2d_1134 (Conv2D)            (None, 25, 25, 48)   9216        max_pooling2d_22[0][0]           
__________________________________________________________________________________________________
conv2d_1137 (Conv2D)            (None, 25, 25, 96)   55296       activation_1133[0][0]            
__________________________________________________________________________________________________
batch_normalization_1066 (Batch (None, 25, 25, 48)   144         conv2d_1134[0][0]                
__________________________________________________________________________________________________
batch_normalization_1069 (Batch (None, 25, 25, 96)   288         conv2d_1137[0][0]                
__________________________________________________________________________________________________
activation_1131 (Activation)    (None, 25, 25, 48)   0           batch_normalization_1066[0][0]   
__________________________________________________________________________________________________
activation_1134 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1069[0][0]   
__________________________________________________________________________________________________
average_pooling2d_20 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_22[0][0]           
__________________________________________________________________________________________________
conv2d_1133 (Conv2D)            (None, 25, 25, 64)   12288       max_pooling2d_22[0][0]           
__________________________________________________________________________________________________
conv2d_1135 (Conv2D)            (None, 25, 25, 64)   76800       activation_1131[0][0]            
__________________________________________________________________________________________________
conv2d_1138 (Conv2D)            (None, 25, 25, 96)   82944       activation_1134[0][0]            
__________________________________________________________________________________________________
conv2d_1139 (Conv2D)            (None, 25, 25, 32)   6144        average_pooling2d_20[0][0]       
__________________________________________________________________________________________________
batch_normalization_1065 (Batch (None, 25, 25, 64)   192         conv2d_1133[0][0]                
__________________________________________________________________________________________________
batch_normalization_1067 (Batch (None, 25, 25, 64)   192         conv2d_1135[0][0]                
__________________________________________________________________________________________________
batch_normalization_1070 (Batch (None, 25, 25, 96)   288         conv2d_1138[0][0]                
__________________________________________________________________________________________________
batch_normalization_1071 (Batch (None, 25, 25, 32)   96          conv2d_1139[0][0]                
__________________________________________________________________________________________________
activation_1130 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1065[0][0]   
__________________________________________________________________________________________________
activation_1132 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1067[0][0]   
__________________________________________________________________________________________________
activation_1135 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1070[0][0]   
__________________________________________________________________________________________________
activation_1136 (Activation)    (None, 25, 25, 32)   0           batch_normalization_1071[0][0]   
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_1130[0][0]            
                                                                 activation_1132[0][0]            
                                                                 activation_1135[0][0]            
                                                                 activation_1136[0][0]            
__________________________________________________________________________________________________
conv2d_1143 (Conv2D)            (None, 25, 25, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1075 (Batch (None, 25, 25, 64)   192         conv2d_1143[0][0]                
__________________________________________________________________________________________________
activation_1140 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1075[0][0]   
__________________________________________________________________________________________________
conv2d_1141 (Conv2D)            (None, 25, 25, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_1144 (Conv2D)            (None, 25, 25, 96)   55296       activation_1140[0][0]            
__________________________________________________________________________________________________
batch_normalization_1073 (Batch (None, 25, 25, 48)   144         conv2d_1141[0][0]                
__________________________________________________________________________________________________
batch_normalization_1076 (Batch (None, 25, 25, 96)   288         conv2d_1144[0][0]                
__________________________________________________________________________________________________
activation_1138 (Activation)    (None, 25, 25, 48)   0           batch_normalization_1073[0][0]   
__________________________________________________________________________________________________
activation_1141 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1076[0][0]   
__________________________________________________________________________________________________
average_pooling2d_21 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_1140 (Conv2D)            (None, 25, 25, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_1142 (Conv2D)            (None, 25, 25, 64)   76800       activation_1138[0][0]            
__________________________________________________________________________________________________
conv2d_1145 (Conv2D)            (None, 25, 25, 96)   82944       activation_1141[0][0]            
__________________________________________________________________________________________________
conv2d_1146 (Conv2D)            (None, 25, 25, 64)   16384       average_pooling2d_21[0][0]       
__________________________________________________________________________________________________
batch_normalization_1072 (Batch (None, 25, 25, 64)   192         conv2d_1140[0][0]                
__________________________________________________________________________________________________
batch_normalization_1074 (Batch (None, 25, 25, 64)   192         conv2d_1142[0][0]                
__________________________________________________________________________________________________
batch_normalization_1077 (Batch (None, 25, 25, 96)   288         conv2d_1145[0][0]                
__________________________________________________________________________________________________
batch_normalization_1078 (Batch (None, 25, 25, 64)   192         conv2d_1146[0][0]                
__________________________________________________________________________________________________
activation_1137 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1072[0][0]   
__________________________________________________________________________________________________
activation_1139 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1074[0][0]   
__________________________________________________________________________________________________
activation_1142 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1077[0][0]   
__________________________________________________________________________________________________
activation_1143 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1078[0][0]   
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_1137[0][0]            
                                                                 activation_1139[0][0]            
                                                                 activation_1142[0][0]            
                                                                 activation_1143[0][0]            
__________________________________________________________________________________________________
conv2d_1150 (Conv2D)            (None, 25, 25, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1082 (Batch (None, 25, 25, 64)   192         conv2d_1150[0][0]                
__________________________________________________________________________________________________
activation_1147 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1082[0][0]   
__________________________________________________________________________________________________
conv2d_1148 (Conv2D)            (None, 25, 25, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_1151 (Conv2D)            (None, 25, 25, 96)   55296       activation_1147[0][0]            
__________________________________________________________________________________________________
batch_normalization_1080 (Batch (None, 25, 25, 48)   144         conv2d_1148[0][0]                
__________________________________________________________________________________________________
batch_normalization_1083 (Batch (None, 25, 25, 96)   288         conv2d_1151[0][0]                
__________________________________________________________________________________________________
activation_1145 (Activation)    (None, 25, 25, 48)   0           batch_normalization_1080[0][0]   
__________________________________________________________________________________________________
activation_1148 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1083[0][0]   
__________________________________________________________________________________________________
average_pooling2d_22 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_1147 (Conv2D)            (None, 25, 25, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_1149 (Conv2D)            (None, 25, 25, 64)   76800       activation_1145[0][0]            
__________________________________________________________________________________________________
conv2d_1152 (Conv2D)            (None, 25, 25, 96)   82944       activation_1148[0][0]            
__________________________________________________________________________________________________
conv2d_1153 (Conv2D)            (None, 25, 25, 64)   18432       average_pooling2d_22[0][0]       
__________________________________________________________________________________________________
batch_normalization_1079 (Batch (None, 25, 25, 64)   192         conv2d_1147[0][0]                
__________________________________________________________________________________________________
batch_normalization_1081 (Batch (None, 25, 25, 64)   192         conv2d_1149[0][0]                
__________________________________________________________________________________________________
batch_normalization_1084 (Batch (None, 25, 25, 96)   288         conv2d_1152[0][0]                
__________________________________________________________________________________________________
batch_normalization_1085 (Batch (None, 25, 25, 64)   192         conv2d_1153[0][0]                
__________________________________________________________________________________________________
activation_1144 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1079[0][0]   
__________________________________________________________________________________________________
activation_1146 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1081[0][0]   
__________________________________________________________________________________________________
activation_1149 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1084[0][0]   
__________________________________________________________________________________________________
activation_1150 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1085[0][0]   
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_1144[0][0]            
                                                                 activation_1146[0][0]            
                                                                 activation_1149[0][0]            
                                                                 activation_1150[0][0]            
__________________________________________________________________________________________________
conv2d_1155 (Conv2D)            (None, 25, 25, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1087 (Batch (None, 25, 25, 64)   192         conv2d_1155[0][0]                
__________________________________________________________________________________________________
activation_1152 (Activation)    (None, 25, 25, 64)   0           batch_normalization_1087[0][0]   
__________________________________________________________________________________________________
conv2d_1156 (Conv2D)            (None, 25, 25, 96)   55296       activation_1152[0][0]            
__________________________________________________________________________________________________
batch_normalization_1088 (Batch (None, 25, 25, 96)   288         conv2d_1156[0][0]                
__________________________________________________________________________________________________
activation_1153 (Activation)    (None, 25, 25, 96)   0           batch_normalization_1088[0][0]   
__________________________________________________________________________________________________
conv2d_1154 (Conv2D)            (None, 12, 12, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_1157 (Conv2D)            (None, 12, 12, 96)   82944       activation_1153[0][0]            
__________________________________________________________________________________________________
batch_normalization_1086 (Batch (None, 12, 12, 384)  1152        conv2d_1154[0][0]                
__________________________________________________________________________________________________
batch_normalization_1089 (Batch (None, 12, 12, 96)   288         conv2d_1157[0][0]                
__________________________________________________________________________________________________
activation_1151 (Activation)    (None, 12, 12, 384)  0           batch_normalization_1086[0][0]   
__________________________________________________________________________________________________
activation_1154 (Activation)    (None, 12, 12, 96)   0           batch_normalization_1089[0][0]   
__________________________________________________________________________________________________
max_pooling2d_23 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_1151[0][0]            
                                                                 activation_1154[0][0]            
                                                                 max_pooling2d_23[0][0]           
__________________________________________________________________________________________________
conv2d_1162 (Conv2D)            (None, 12, 12, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1094 (Batch (None, 12, 12, 128)  384         conv2d_1162[0][0]                
__________________________________________________________________________________________________
activation_1159 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1094[0][0]   
__________________________________________________________________________________________________
conv2d_1163 (Conv2D)            (None, 12, 12, 128)  114688      activation_1159[0][0]            
__________________________________________________________________________________________________
batch_normalization_1095 (Batch (None, 12, 12, 128)  384         conv2d_1163[0][0]                
__________________________________________________________________________________________________
activation_1160 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1095[0][0]   
__________________________________________________________________________________________________
conv2d_1159 (Conv2D)            (None, 12, 12, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_1164 (Conv2D)            (None, 12, 12, 128)  114688      activation_1160[0][0]            
__________________________________________________________________________________________________
batch_normalization_1091 (Batch (None, 12, 12, 128)  384         conv2d_1159[0][0]                
__________________________________________________________________________________________________
batch_normalization_1096 (Batch (None, 12, 12, 128)  384         conv2d_1164[0][0]                
__________________________________________________________________________________________________
activation_1156 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1091[0][0]   
__________________________________________________________________________________________________
activation_1161 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1096[0][0]   
__________________________________________________________________________________________________
conv2d_1160 (Conv2D)            (None, 12, 12, 128)  114688      activation_1156[0][0]            
__________________________________________________________________________________________________
conv2d_1165 (Conv2D)            (None, 12, 12, 128)  114688      activation_1161[0][0]            
__________________________________________________________________________________________________
batch_normalization_1092 (Batch (None, 12, 12, 128)  384         conv2d_1160[0][0]                
__________________________________________________________________________________________________
batch_normalization_1097 (Batch (None, 12, 12, 128)  384         conv2d_1165[0][0]                
__________________________________________________________________________________________________
activation_1157 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1092[0][0]   
__________________________________________________________________________________________________
activation_1162 (Activation)    (None, 12, 12, 128)  0           batch_normalization_1097[0][0]   
__________________________________________________________________________________________________
average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_1158 (Conv2D)            (None, 12, 12, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_1161 (Conv2D)            (None, 12, 12, 192)  172032      activation_1157[0][0]            
__________________________________________________________________________________________________
conv2d_1166 (Conv2D)            (None, 12, 12, 192)  172032      activation_1162[0][0]            
__________________________________________________________________________________________________
conv2d_1167 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       
__________________________________________________________________________________________________
batch_normalization_1090 (Batch (None, 12, 12, 192)  576         conv2d_1158[0][0]                
__________________________________________________________________________________________________
batch_normalization_1093 (Batch (None, 12, 12, 192)  576         conv2d_1161[0][0]                
__________________________________________________________________________________________________
batch_normalization_1098 (Batch (None, 12, 12, 192)  576         conv2d_1166[0][0]                
__________________________________________________________________________________________________
batch_normalization_1099 (Batch (None, 12, 12, 192)  576         conv2d_1167[0][0]                
__________________________________________________________________________________________________
activation_1155 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1090[0][0]   
__________________________________________________________________________________________________
activation_1158 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1093[0][0]   
__________________________________________________________________________________________________
activation_1163 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1098[0][0]   
__________________________________________________________________________________________________
activation_1164 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1099[0][0]   
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_1155[0][0]            
                                                                 activation_1158[0][0]            
                                                                 activation_1163[0][0]            
                                                                 activation_1164[0][0]            
__________________________________________________________________________________________________
conv2d_1172 (Conv2D)            (None, 12, 12, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1104 (Batch (None, 12, 12, 160)  480         conv2d_1172[0][0]                
__________________________________________________________________________________________________
activation_1169 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1104[0][0]   
__________________________________________________________________________________________________
conv2d_1173 (Conv2D)            (None, 12, 12, 160)  179200      activation_1169[0][0]            
__________________________________________________________________________________________________
batch_normalization_1105 (Batch (None, 12, 12, 160)  480         conv2d_1173[0][0]                
__________________________________________________________________________________________________
activation_1170 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1105[0][0]   
__________________________________________________________________________________________________
conv2d_1169 (Conv2D)            (None, 12, 12, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_1174 (Conv2D)            (None, 12, 12, 160)  179200      activation_1170[0][0]            
__________________________________________________________________________________________________
batch_normalization_1101 (Batch (None, 12, 12, 160)  480         conv2d_1169[0][0]                
__________________________________________________________________________________________________
batch_normalization_1106 (Batch (None, 12, 12, 160)  480         conv2d_1174[0][0]                
__________________________________________________________________________________________________
activation_1166 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1101[0][0]   
__________________________________________________________________________________________________
activation_1171 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1106[0][0]   
__________________________________________________________________________________________________
conv2d_1170 (Conv2D)            (None, 12, 12, 160)  179200      activation_1166[0][0]            
__________________________________________________________________________________________________
conv2d_1175 (Conv2D)            (None, 12, 12, 160)  179200      activation_1171[0][0]            
__________________________________________________________________________________________________
batch_normalization_1102 (Batch (None, 12, 12, 160)  480         conv2d_1170[0][0]                
__________________________________________________________________________________________________
batch_normalization_1107 (Batch (None, 12, 12, 160)  480         conv2d_1175[0][0]                
__________________________________________________________________________________________________
activation_1167 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1102[0][0]   
__________________________________________________________________________________________________
activation_1172 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1107[0][0]   
__________________________________________________________________________________________________
average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_1168 (Conv2D)            (None, 12, 12, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_1171 (Conv2D)            (None, 12, 12, 192)  215040      activation_1167[0][0]            
__________________________________________________________________________________________________
conv2d_1176 (Conv2D)            (None, 12, 12, 192)  215040      activation_1172[0][0]            
__________________________________________________________________________________________________
conv2d_1177 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       
__________________________________________________________________________________________________
batch_normalization_1100 (Batch (None, 12, 12, 192)  576         conv2d_1168[0][0]                
__________________________________________________________________________________________________
batch_normalization_1103 (Batch (None, 12, 12, 192)  576         conv2d_1171[0][0]                
__________________________________________________________________________________________________
batch_normalization_1108 (Batch (None, 12, 12, 192)  576         conv2d_1176[0][0]                
__________________________________________________________________________________________________
batch_normalization_1109 (Batch (None, 12, 12, 192)  576         conv2d_1177[0][0]                
__________________________________________________________________________________________________
activation_1165 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1100[0][0]   
__________________________________________________________________________________________________
activation_1168 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1103[0][0]   
__________________________________________________________________________________________________
activation_1173 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1108[0][0]   
__________________________________________________________________________________________________
activation_1174 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1109[0][0]   
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_1165[0][0]            
                                                                 activation_1168[0][0]            
                                                                 activation_1173[0][0]            
                                                                 activation_1174[0][0]            
__________________________________________________________________________________________________
conv2d_1182 (Conv2D)            (None, 12, 12, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1114 (Batch (None, 12, 12, 160)  480         conv2d_1182[0][0]                
__________________________________________________________________________________________________
activation_1179 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1114[0][0]   
__________________________________________________________________________________________________
conv2d_1183 (Conv2D)            (None, 12, 12, 160)  179200      activation_1179[0][0]            
__________________________________________________________________________________________________
batch_normalization_1115 (Batch (None, 12, 12, 160)  480         conv2d_1183[0][0]                
__________________________________________________________________________________________________
activation_1180 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1115[0][0]   
__________________________________________________________________________________________________
conv2d_1179 (Conv2D)            (None, 12, 12, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_1184 (Conv2D)            (None, 12, 12, 160)  179200      activation_1180[0][0]            
__________________________________________________________________________________________________
batch_normalization_1111 (Batch (None, 12, 12, 160)  480         conv2d_1179[0][0]                
__________________________________________________________________________________________________
batch_normalization_1116 (Batch (None, 12, 12, 160)  480         conv2d_1184[0][0]                
__________________________________________________________________________________________________
activation_1176 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1111[0][0]   
__________________________________________________________________________________________________
activation_1181 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1116[0][0]   
__________________________________________________________________________________________________
conv2d_1180 (Conv2D)            (None, 12, 12, 160)  179200      activation_1176[0][0]            
__________________________________________________________________________________________________
conv2d_1185 (Conv2D)            (None, 12, 12, 160)  179200      activation_1181[0][0]            
__________________________________________________________________________________________________
batch_normalization_1112 (Batch (None, 12, 12, 160)  480         conv2d_1180[0][0]                
__________________________________________________________________________________________________
batch_normalization_1117 (Batch (None, 12, 12, 160)  480         conv2d_1185[0][0]                
__________________________________________________________________________________________________
activation_1177 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1112[0][0]   
__________________________________________________________________________________________________
activation_1182 (Activation)    (None, 12, 12, 160)  0           batch_normalization_1117[0][0]   
__________________________________________________________________________________________________
average_pooling2d_25 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_1178 (Conv2D)            (None, 12, 12, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_1181 (Conv2D)            (None, 12, 12, 192)  215040      activation_1177[0][0]            
__________________________________________________________________________________________________
conv2d_1186 (Conv2D)            (None, 12, 12, 192)  215040      activation_1182[0][0]            
__________________________________________________________________________________________________
conv2d_1187 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_25[0][0]       
__________________________________________________________________________________________________
batch_normalization_1110 (Batch (None, 12, 12, 192)  576         conv2d_1178[0][0]                
__________________________________________________________________________________________________
batch_normalization_1113 (Batch (None, 12, 12, 192)  576         conv2d_1181[0][0]                
__________________________________________________________________________________________________
batch_normalization_1118 (Batch (None, 12, 12, 192)  576         conv2d_1186[0][0]                
__________________________________________________________________________________________________
batch_normalization_1119 (Batch (None, 12, 12, 192)  576         conv2d_1187[0][0]                
__________________________________________________________________________________________________
activation_1175 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1110[0][0]   
__________________________________________________________________________________________________
activation_1178 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1113[0][0]   
__________________________________________________________________________________________________
activation_1183 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1118[0][0]   
__________________________________________________________________________________________________
activation_1184 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1119[0][0]   
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_1175[0][0]            
                                                                 activation_1178[0][0]            
                                                                 activation_1183[0][0]            
                                                                 activation_1184[0][0]            
__________________________________________________________________________________________________
conv2d_1192 (Conv2D)            (None, 12, 12, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1124 (Batch (None, 12, 12, 192)  576         conv2d_1192[0][0]                
__________________________________________________________________________________________________
activation_1189 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1124[0][0]   
__________________________________________________________________________________________________
conv2d_1193 (Conv2D)            (None, 12, 12, 192)  258048      activation_1189[0][0]            
__________________________________________________________________________________________________
batch_normalization_1125 (Batch (None, 12, 12, 192)  576         conv2d_1193[0][0]                
__________________________________________________________________________________________________
activation_1190 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1125[0][0]   
__________________________________________________________________________________________________
conv2d_1189 (Conv2D)            (None, 12, 12, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_1194 (Conv2D)            (None, 12, 12, 192)  258048      activation_1190[0][0]            
__________________________________________________________________________________________________
batch_normalization_1121 (Batch (None, 12, 12, 192)  576         conv2d_1189[0][0]                
__________________________________________________________________________________________________
batch_normalization_1126 (Batch (None, 12, 12, 192)  576         conv2d_1194[0][0]                
__________________________________________________________________________________________________
activation_1186 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1121[0][0]   
__________________________________________________________________________________________________
activation_1191 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1126[0][0]   
__________________________________________________________________________________________________
conv2d_1190 (Conv2D)            (None, 12, 12, 192)  258048      activation_1186[0][0]            
__________________________________________________________________________________________________
conv2d_1195 (Conv2D)            (None, 12, 12, 192)  258048      activation_1191[0][0]            
__________________________________________________________________________________________________
batch_normalization_1122 (Batch (None, 12, 12, 192)  576         conv2d_1190[0][0]                
__________________________________________________________________________________________________
batch_normalization_1127 (Batch (None, 12, 12, 192)  576         conv2d_1195[0][0]                
__________________________________________________________________________________________________
activation_1187 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1122[0][0]   
__________________________________________________________________________________________________
activation_1192 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1127[0][0]   
__________________________________________________________________________________________________
average_pooling2d_26 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_1188 (Conv2D)            (None, 12, 12, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_1191 (Conv2D)            (None, 12, 12, 192)  258048      activation_1187[0][0]            
__________________________________________________________________________________________________
conv2d_1196 (Conv2D)            (None, 12, 12, 192)  258048      activation_1192[0][0]            
__________________________________________________________________________________________________
conv2d_1197 (Conv2D)            (None, 12, 12, 192)  147456      average_pooling2d_26[0][0]       
__________________________________________________________________________________________________
batch_normalization_1120 (Batch (None, 12, 12, 192)  576         conv2d_1188[0][0]                
__________________________________________________________________________________________________
batch_normalization_1123 (Batch (None, 12, 12, 192)  576         conv2d_1191[0][0]                
__________________________________________________________________________________________________
batch_normalization_1128 (Batch (None, 12, 12, 192)  576         conv2d_1196[0][0]                
__________________________________________________________________________________________________
batch_normalization_1129 (Batch (None, 12, 12, 192)  576         conv2d_1197[0][0]                
__________________________________________________________________________________________________
activation_1185 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1120[0][0]   
__________________________________________________________________________________________________
activation_1188 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1123[0][0]   
__________________________________________________________________________________________________
activation_1193 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1128[0][0]   
__________________________________________________________________________________________________
activation_1194 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1129[0][0]   
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_1185[0][0]            
                                                                 activation_1188[0][0]            
                                                                 activation_1193[0][0]            
                                                                 activation_1194[0][0]            
__________________________________________________________________________________________________
conv2d_1200 (Conv2D)            (None, 12, 12, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1132 (Batch (None, 12, 12, 192)  576         conv2d_1200[0][0]                
__________________________________________________________________________________________________
activation_1197 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1132[0][0]   
__________________________________________________________________________________________________
conv2d_1201 (Conv2D)            (None, 12, 12, 192)  258048      activation_1197[0][0]            
__________________________________________________________________________________________________
batch_normalization_1133 (Batch (None, 12, 12, 192)  576         conv2d_1201[0][0]                
__________________________________________________________________________________________________
activation_1198 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1133[0][0]   
__________________________________________________________________________________________________
conv2d_1198 (Conv2D)            (None, 12, 12, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_1202 (Conv2D)            (None, 12, 12, 192)  258048      activation_1198[0][0]            
__________________________________________________________________________________________________
batch_normalization_1130 (Batch (None, 12, 12, 192)  576         conv2d_1198[0][0]                
__________________________________________________________________________________________________
batch_normalization_1134 (Batch (None, 12, 12, 192)  576         conv2d_1202[0][0]                
__________________________________________________________________________________________________
activation_1195 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1130[0][0]   
__________________________________________________________________________________________________
activation_1199 (Activation)    (None, 12, 12, 192)  0           batch_normalization_1134[0][0]   
__________________________________________________________________________________________________
conv2d_1199 (Conv2D)            (None, 5, 5, 320)    552960      activation_1195[0][0]            
__________________________________________________________________________________________________
conv2d_1203 (Conv2D)            (None, 5, 5, 192)    331776      activation_1199[0][0]            
__________________________________________________________________________________________________
batch_normalization_1131 (Batch (None, 5, 5, 320)    960         conv2d_1199[0][0]                
__________________________________________________________________________________________________
batch_normalization_1135 (Batch (None, 5, 5, 192)    576         conv2d_1203[0][0]                
__________________________________________________________________________________________________
activation_1196 (Activation)    (None, 5, 5, 320)    0           batch_normalization_1131[0][0]   
__________________________________________________________________________________________________
activation_1200 (Activation)    (None, 5, 5, 192)    0           batch_normalization_1135[0][0]   
__________________________________________________________________________________________________
max_pooling2d_24 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_1196[0][0]            
                                                                 activation_1200[0][0]            
                                                                 max_pooling2d_24[0][0]           
__________________________________________________________________________________________________
conv2d_1208 (Conv2D)            (None, 5, 5, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1140 (Batch (None, 5, 5, 448)    1344        conv2d_1208[0][0]                
__________________________________________________________________________________________________
activation_1205 (Activation)    (None, 5, 5, 448)    0           batch_normalization_1140[0][0]   
__________________________________________________________________________________________________
conv2d_1205 (Conv2D)            (None, 5, 5, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_1209 (Conv2D)            (None, 5, 5, 384)    1548288     activation_1205[0][0]            
__________________________________________________________________________________________________
batch_normalization_1137 (Batch (None, 5, 5, 384)    1152        conv2d_1205[0][0]                
__________________________________________________________________________________________________
batch_normalization_1141 (Batch (None, 5, 5, 384)    1152        conv2d_1209[0][0]                
__________________________________________________________________________________________________
activation_1202 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1137[0][0]   
__________________________________________________________________________________________________
activation_1206 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1141[0][0]   
__________________________________________________________________________________________________
conv2d_1206 (Conv2D)            (None, 5, 5, 384)    442368      activation_1202[0][0]            
__________________________________________________________________________________________________
conv2d_1207 (Conv2D)            (None, 5, 5, 384)    442368      activation_1202[0][0]            
__________________________________________________________________________________________________
conv2d_1210 (Conv2D)            (None, 5, 5, 384)    442368      activation_1206[0][0]            
__________________________________________________________________________________________________
conv2d_1211 (Conv2D)            (None, 5, 5, 384)    442368      activation_1206[0][0]            
__________________________________________________________________________________________________
average_pooling2d_27 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_1204 (Conv2D)            (None, 5, 5, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1138 (Batch (None, 5, 5, 384)    1152        conv2d_1206[0][0]                
__________________________________________________________________________________________________
batch_normalization_1139 (Batch (None, 5, 5, 384)    1152        conv2d_1207[0][0]                
__________________________________________________________________________________________________
batch_normalization_1142 (Batch (None, 5, 5, 384)    1152        conv2d_1210[0][0]                
__________________________________________________________________________________________________
batch_normalization_1143 (Batch (None, 5, 5, 384)    1152        conv2d_1211[0][0]                
__________________________________________________________________________________________________
conv2d_1212 (Conv2D)            (None, 5, 5, 192)    245760      average_pooling2d_27[0][0]       
__________________________________________________________________________________________________
batch_normalization_1136 (Batch (None, 5, 5, 320)    960         conv2d_1204[0][0]                
__________________________________________________________________________________________________
activation_1203 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1138[0][0]   
__________________________________________________________________________________________________
activation_1204 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1139[0][0]   
__________________________________________________________________________________________________
activation_1207 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1142[0][0]   
__________________________________________________________________________________________________
activation_1208 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1143[0][0]   
__________________________________________________________________________________________________
batch_normalization_1144 (Batch (None, 5, 5, 192)    576         conv2d_1212[0][0]                
__________________________________________________________________________________________________
activation_1201 (Activation)    (None, 5, 5, 320)    0           batch_normalization_1136[0][0]   
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_1203[0][0]            
                                                                 activation_1204[0][0]            
__________________________________________________________________________________________________
concatenate_404 (Concatenate)   (None, 5, 5, 768)    0           activation_1207[0][0]            
                                                                 activation_1208[0][0]            
__________________________________________________________________________________________________
activation_1209 (Activation)    (None, 5, 5, 192)    0           batch_normalization_1144[0][0]   
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_1201[0][0]            
                                                                 mixed9_0[0][0]                   
                                                                 concatenate_404[0][0]            
                                                                 activation_1209[0][0]            
__________________________________________________________________________________________________
conv2d_1217 (Conv2D)            (None, 5, 5, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1149 (Batch (None, 5, 5, 448)    1344        conv2d_1217[0][0]                
__________________________________________________________________________________________________
activation_1214 (Activation)    (None, 5, 5, 448)    0           batch_normalization_1149[0][0]   
__________________________________________________________________________________________________
conv2d_1214 (Conv2D)            (None, 5, 5, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_1218 (Conv2D)            (None, 5, 5, 384)    1548288     activation_1214[0][0]            
__________________________________________________________________________________________________
batch_normalization_1146 (Batch (None, 5, 5, 384)    1152        conv2d_1214[0][0]                
__________________________________________________________________________________________________
batch_normalization_1150 (Batch (None, 5, 5, 384)    1152        conv2d_1218[0][0]                
__________________________________________________________________________________________________
activation_1211 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1146[0][0]   
__________________________________________________________________________________________________
activation_1215 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1150[0][0]   
__________________________________________________________________________________________________
conv2d_1215 (Conv2D)            (None, 5, 5, 384)    442368      activation_1211[0][0]            
__________________________________________________________________________________________________
conv2d_1216 (Conv2D)            (None, 5, 5, 384)    442368      activation_1211[0][0]            
__________________________________________________________________________________________________
conv2d_1219 (Conv2D)            (None, 5, 5, 384)    442368      activation_1215[0][0]            
__________________________________________________________________________________________________
conv2d_1220 (Conv2D)            (None, 5, 5, 384)    442368      activation_1215[0][0]            
__________________________________________________________________________________________________
average_pooling2d_28 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_1213 (Conv2D)            (None, 5, 5, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1147 (Batch (None, 5, 5, 384)    1152        conv2d_1215[0][0]                
__________________________________________________________________________________________________
batch_normalization_1148 (Batch (None, 5, 5, 384)    1152        conv2d_1216[0][0]                
__________________________________________________________________________________________________
batch_normalization_1151 (Batch (None, 5, 5, 384)    1152        conv2d_1219[0][0]                
__________________________________________________________________________________________________
batch_normalization_1152 (Batch (None, 5, 5, 384)    1152        conv2d_1220[0][0]                
__________________________________________________________________________________________________
conv2d_1221 (Conv2D)            (None, 5, 5, 192)    393216      average_pooling2d_28[0][0]       
__________________________________________________________________________________________________
batch_normalization_1145 (Batch (None, 5, 5, 320)    960         conv2d_1213[0][0]                
__________________________________________________________________________________________________
activation_1212 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1147[0][0]   
__________________________________________________________________________________________________
activation_1213 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1148[0][0]   
__________________________________________________________________________________________________
activation_1216 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1151[0][0]   
__________________________________________________________________________________________________
activation_1217 (Activation)    (None, 5, 5, 384)    0           batch_normalization_1152[0][0]   
__________________________________________________________________________________________________
batch_normalization_1153 (Batch (None, 5, 5, 192)    576         conv2d_1221[0][0]                
__________________________________________________________________________________________________
activation_1210 (Activation)    (None, 5, 5, 320)    0           batch_normalization_1145[0][0]   
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_1212[0][0]            
                                                                 activation_1213[0][0]            
__________________________________________________________________________________________________
concatenate_405 (Concatenate)   (None, 5, 5, 768)    0           activation_1216[0][0]            
                                                                 activation_1217[0][0]            
__________________________________________________________________________________________________
activation_1218 (Activation)    (None, 5, 5, 192)    0           batch_normalization_1153[0][0]   
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_1210[0][0]            
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_405[0][0]            
                                                                 activation_1218[0][0]            
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    
__________________________________________________________________________________________________
predictions (Dense)             (None, 10)           20490       avg_pool[0][0]                   
==================================================================================================
Total params: 21,823,274
Trainable params: 21,788,842
Non-trainable params: 34,432
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
Using Enhanced Data Generation
Found 9000 images belonging to 10 classes.
Found 2000 images belonging to 10 classes.
JSON Mapping for the model classes saved to  /content/drive/My Drive/imageprocessing/idenprof/json/model_class.json
Number of experiments (Epochs) :  25
Epoch 1/25
280/281 [============================>.] - ETA: 0s - loss: 1.7496 - acc: 0.4034Epoch 1/25
 62/281 [=====>........................] - ETA: 1:16 - loss: 6.1076 - acc: 0.2097
Epoch 00001: val_acc improved from -inf to 0.20968, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-001_acc-0.209677.h5
281/281 [==============================] - 832s 3s/step - loss: 1.7477 - acc: 0.4039 - val_loss: 6.1076 - val_acc: 0.2097
Epoch 2/25
280/281 [============================>.] - ETA: 0s - loss: 1.4101 - acc: 0.5169Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 2.2347 - acc: 0.4214
Epoch 00002: val_acc improved from 0.20968 to 0.42137, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-002_acc-0.421371.h5
281/281 [==============================] - 211s 751ms/step - loss: 1.4097 - acc: 0.5168 - val_loss: 2.2347 - val_acc: 0.4214
Epoch 3/25
280/281 [============================>.] - ETA: 0s - loss: 1.2555 - acc: 0.5667Epoch 1/25
 62/281 [=====>........................] - ETA: 40s - loss: 1.6257 - acc: 0.4849
Epoch 00003: val_acc improved from 0.42137 to 0.48488, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-003_acc-0.484879.h5
281/281 [==============================] - 212s 753ms/step - loss: 1.2558 - acc: 0.5666 - val_loss: 1.6257 - val_acc: 0.4849
Epoch 4/25
280/281 [============================>.] - ETA: 0s - loss: 1.1398 - acc: 0.6122Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 2.0938 - acc: 0.4103
Epoch 00004: val_acc did not improve from 0.48488
281/281 [==============================] - 210s 746ms/step - loss: 1.1396 - acc: 0.6124 - val_loss: 2.0938 - val_acc: 0.4103
Epoch 5/25
280/281 [============================>.] - ETA: 0s - loss: 1.0587 - acc: 0.6319Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 2.4631 - acc: 0.4153
Epoch 00005: val_acc did not improve from 0.48488
281/281 [==============================] - 209s 744ms/step - loss: 1.0596 - acc: 0.6315 - val_loss: 2.4631 - val_acc: 0.4153
Epoch 6/25
280/281 [============================>.] - ETA: 0s - loss: 0.9977 - acc: 0.6572Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 1.3106 - acc: 0.6013
Epoch 00006: val_acc improved from 0.48488 to 0.60131, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-006_acc-0.601310.h5
281/281 [==============================] - 211s 752ms/step - loss: 0.9990 - acc: 0.6570 - val_loss: 1.3106 - val_acc: 0.6013
Epoch 7/25
280/281 [============================>.] - ETA: 0s - loss: 0.9352 - acc: 0.6764Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 14.3799 - acc: 0.5469
Epoch 00007: val_acc did not improve from 0.60131
281/281 [==============================] - 209s 745ms/step - loss: 0.9350 - acc: 0.6764 - val_loss: 14.3799 - val_acc: 0.5469
Epoch 8/25
280/281 [============================>.] - ETA: 0s - loss: 0.8466 - acc: 0.7098Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 1.4631 - acc: 0.5554
Epoch 00008: val_acc did not improve from 0.60131
281/281 [==============================] - 209s 744ms/step - loss: 0.8461 - acc: 0.7099 - val_loss: 1.4631 - val_acc: 0.5554
Epoch 9/25
280/281 [============================>.] - ETA: 0s - loss: 0.7958 - acc: 0.7254Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 2.4050 - acc: 0.4567
Epoch 00009: val_acc did not improve from 0.60131
281/281 [==============================] - 209s 745ms/step - loss: 0.7951 - acc: 0.7256 - val_loss: 2.4050 - val_acc: 0.4567
Epoch 10/25
280/281 [============================>.] - ETA: 0s - loss: 0.7365 - acc: 0.7519Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 1.2742 - acc: 0.6240
Epoch 00010: val_acc improved from 0.60131 to 0.62399, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-010_acc-0.623992.h5
281/281 [==============================] - 212s 753ms/step - loss: 0.7354 - acc: 0.7522 - val_loss: 1.2742 - val_acc: 0.6240
Epoch 11/25
280/281 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.7574Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 1.0077 - acc: 0.6850
Epoch 00011: val_acc improved from 0.62399 to 0.68498, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-011_acc-0.684980.h5
281/281 [==============================] - 212s 754ms/step - loss: 0.6933 - acc: 0.7576 - val_loss: 1.0077 - val_acc: 0.6850
Epoch 12/25
280/281 [============================>.] - ETA: 0s - loss: 0.5057 - acc: 0.8290Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5868 - acc: 0.7878
Epoch 00012: val_acc improved from 0.68498 to 0.78780, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-012_acc-0.787802.h5
281/281 [==============================] - 212s 754ms/step - loss: 0.5054 - acc: 0.8291 - val_loss: 0.5868 - val_acc: 0.7878
Epoch 13/25
280/281 [============================>.] - ETA: 0s - loss: 0.4314 - acc: 0.8531Epoch 1/25
 62/281 [=====>........................] - ETA: 42s - loss: 0.5585 - acc: 0.8024
Epoch 00013: val_acc improved from 0.78780 to 0.80242, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-013_acc-0.802419.h5
281/281 [==============================] - 212s 754ms/step - loss: 0.4321 - acc: 0.8530 - val_loss: 0.5585 - val_acc: 0.8024
Epoch 14/25
280/281 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8617Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5809 - acc: 0.7949
Epoch 00014: val_acc did not improve from 0.80242
281/281 [==============================] - 210s 746ms/step - loss: 0.3967 - acc: 0.8616 - val_loss: 0.5809 - val_acc: 0.7949
Epoch 15/25
280/281 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.8768Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5587 - acc: 0.8145
Epoch 00015: val_acc improved from 0.80242 to 0.81452, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-015_acc-0.814516.h5
281/281 [==============================] - 211s 753ms/step - loss: 0.3691 - acc: 0.8768 - val_loss: 0.5587 - val_acc: 0.8145
Epoch 16/25
280/281 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8791Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.6291 - acc: 0.7959
Epoch 00016: val_acc did not improve from 0.81452
281/281 [==============================] - 210s 746ms/step - loss: 0.3547 - acc: 0.8795 - val_loss: 0.6291 - val_acc: 0.7959
Epoch 17/25
280/281 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.8940Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5441 - acc: 0.8175
Epoch 00017: val_acc improved from 0.81452 to 0.81754, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-017_acc-0.817540.h5
281/281 [==============================] - 212s 753ms/step - loss: 0.3204 - acc: 0.8941 - val_loss: 0.5441 - val_acc: 0.8175
Epoch 18/25
280/281 [============================>.] - ETA: 0s - loss: 0.3046 - acc: 0.8968Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5369 - acc: 0.8211
Epoch 00018: val_acc improved from 0.81754 to 0.82107, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-018_acc-0.821069.h5
281/281 [==============================] - 211s 752ms/step - loss: 0.3051 - acc: 0.8966 - val_loss: 0.5369 - val_acc: 0.8211
Epoch 19/25
280/281 [============================>.] - ETA: 0s - loss: 0.2924 - acc: 0.9002Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5343 - acc: 0.8211
Epoch 00019: val_acc did not improve from 0.82107
281/281 [==============================] - 209s 743ms/step - loss: 0.2921 - acc: 0.9002 - val_loss: 0.5343 - val_acc: 0.8211
Epoch 20/25
280/281 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9014Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5291 - acc: 0.8241
Epoch 00020: val_acc improved from 0.82107 to 0.82409, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-020_acc-0.824093.h5
281/281 [==============================] - 212s 753ms/step - loss: 0.2882 - acc: 0.9013 - val_loss: 0.5291 - val_acc: 0.8241
Epoch 21/25
280/281 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.9029Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5429 - acc: 0.8246
Epoch 00021: val_acc improved from 0.82409 to 0.82460, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-021_acc-0.824597.h5
281/281 [==============================] - 211s 752ms/step - loss: 0.2870 - acc: 0.9027 - val_loss: 0.5429 - val_acc: 0.8246
Epoch 22/25
280/281 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.9071Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5463 - acc: 0.8241
Epoch 00022: val_acc did not improve from 0.82460
281/281 [==============================] - 209s 745ms/step - loss: 0.2768 - acc: 0.9070 - val_loss: 0.5463 - val_acc: 0.8241
Epoch 23/25
280/281 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9085Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5400 - acc: 0.8251
Epoch 00023: val_acc improved from 0.82460 to 0.82510, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-023_acc-0.825101.h5
281/281 [==============================] - 211s 751ms/step - loss: 0.2675 - acc: 0.9086 - val_loss: 0.5400 - val_acc: 0.8251
Epoch 24/25
280/281 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.9053Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5453 - acc: 0.8241
Epoch 00024: val_acc did not improve from 0.82510
281/281 [==============================] - 210s 746ms/step - loss: 0.2829 - acc: 0.9057 - val_loss: 0.5453 - val_acc: 0.8241
Epoch 25/25
280/281 [============================>.] - ETA: 0s - loss: 0.2846 - acc: 0.9019Epoch 1/25
 62/281 [=====>........................] - ETA: 41s - loss: 0.5400 - acc: 0.8226
Epoch 00025: val_acc did not improve from 0.82510
281/281 [==============================] - 209s 744ms/step - loss: 0.2845 - acc: 0.9019 - val_loss: 0.5400 - val_acc: 0.8226
InceptionV3 Model training completed!