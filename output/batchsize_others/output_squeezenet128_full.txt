SqueezeNet Model training starting now!
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_332 (Conv2D)             (None, 111, 111, 64) 1792        input_6[0][0]                    
__________________________________________________________________________________________________
activation_336 (Activation)     (None, 111, 111, 64) 0           conv2d_332[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_18 (MaxPooling2D) (None, 55, 55, 64)   0           activation_336[0][0]             
__________________________________________________________________________________________________
conv2d_333 (Conv2D)             (None, 55, 55, 16)   1040        max_pooling2d_18[0][0]           
__________________________________________________________________________________________________
activation_337 (Activation)     (None, 55, 55, 16)   0           conv2d_333[0][0]                 
__________________________________________________________________________________________________
conv2d_334 (Conv2D)             (None, 55, 55, 64)   1088        activation_337[0][0]             
__________________________________________________________________________________________________
conv2d_335 (Conv2D)             (None, 55, 55, 64)   9280        activation_337[0][0]             
__________________________________________________________________________________________________
activation_338 (Activation)     (None, 55, 55, 64)   0           conv2d_334[0][0]                 
__________________________________________________________________________________________________
activation_339 (Activation)     (None, 55, 55, 64)   0           conv2d_335[0][0]                 
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 55, 55, 128)  0           activation_338[0][0]             
                                                                 activation_339[0][0]             
__________________________________________________________________________________________________
conv2d_336 (Conv2D)             (None, 55, 55, 16)   2064        concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_340 (Activation)     (None, 55, 55, 16)   0           conv2d_336[0][0]                 
__________________________________________________________________________________________________
conv2d_337 (Conv2D)             (None, 55, 55, 64)   1088        activation_340[0][0]             
__________________________________________________________________________________________________
conv2d_338 (Conv2D)             (None, 55, 55, 64)   9280        activation_340[0][0]             
__________________________________________________________________________________________________
activation_341 (Activation)     (None, 55, 55, 64)   0           conv2d_337[0][0]                 
__________________________________________________________________________________________________
activation_342 (Activation)     (None, 55, 55, 64)   0           conv2d_338[0][0]                 
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 55, 55, 128)  0           activation_341[0][0]             
                                                                 activation_342[0][0]             
__________________________________________________________________________________________________
max_pooling2d_19 (MaxPooling2D) (None, 27, 27, 128)  0           concatenate_23[0][0]             
__________________________________________________________________________________________________
conv2d_339 (Conv2D)             (None, 27, 27, 32)   4128        max_pooling2d_19[0][0]           
__________________________________________________________________________________________________
activation_343 (Activation)     (None, 27, 27, 32)   0           conv2d_339[0][0]                 
__________________________________________________________________________________________________
conv2d_340 (Conv2D)             (None, 27, 27, 128)  4224        activation_343[0][0]             
__________________________________________________________________________________________________
conv2d_341 (Conv2D)             (None, 27, 27, 128)  36992       activation_343[0][0]             
__________________________________________________________________________________________________
activation_344 (Activation)     (None, 27, 27, 128)  0           conv2d_340[0][0]                 
__________________________________________________________________________________________________
activation_345 (Activation)     (None, 27, 27, 128)  0           conv2d_341[0][0]                 
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 27, 27, 256)  0           activation_344[0][0]             
                                                                 activation_345[0][0]             
__________________________________________________________________________________________________
conv2d_342 (Conv2D)             (None, 27, 27, 32)   8224        concatenate_24[0][0]             
__________________________________________________________________________________________________
activation_346 (Activation)     (None, 27, 27, 32)   0           conv2d_342[0][0]                 
__________________________________________________________________________________________________
conv2d_343 (Conv2D)             (None, 27, 27, 128)  4224        activation_346[0][0]             
__________________________________________________________________________________________________
conv2d_344 (Conv2D)             (None, 27, 27, 128)  36992       activation_346[0][0]             
__________________________________________________________________________________________________
activation_347 (Activation)     (None, 27, 27, 128)  0           conv2d_343[0][0]                 
__________________________________________________________________________________________________
activation_348 (Activation)     (None, 27, 27, 128)  0           conv2d_344[0][0]                 
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 27, 27, 256)  0           activation_347[0][0]             
                                                                 activation_348[0][0]             
__________________________________________________________________________________________________
max_pooling2d_20 (MaxPooling2D) (None, 13, 13, 256)  0           concatenate_25[0][0]             
__________________________________________________________________________________________________
conv2d_345 (Conv2D)             (None, 13, 13, 48)   12336       max_pooling2d_20[0][0]           
__________________________________________________________________________________________________
activation_349 (Activation)     (None, 13, 13, 48)   0           conv2d_345[0][0]                 
__________________________________________________________________________________________________
conv2d_346 (Conv2D)             (None, 13, 13, 192)  9408        activation_349[0][0]             
__________________________________________________________________________________________________
conv2d_347 (Conv2D)             (None, 13, 13, 192)  83136       activation_349[0][0]             
__________________________________________________________________________________________________
activation_350 (Activation)     (None, 13, 13, 192)  0           conv2d_346[0][0]                 
__________________________________________________________________________________________________
activation_351 (Activation)     (None, 13, 13, 192)  0           conv2d_347[0][0]                 
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 13, 13, 384)  0           activation_350[0][0]             
                                                                 activation_351[0][0]             
__________________________________________________________________________________________________
conv2d_348 (Conv2D)             (None, 13, 13, 48)   18480       concatenate_26[0][0]             
__________________________________________________________________________________________________
activation_352 (Activation)     (None, 13, 13, 48)   0           conv2d_348[0][0]                 
__________________________________________________________________________________________________
conv2d_349 (Conv2D)             (None, 13, 13, 192)  9408        activation_352[0][0]             
__________________________________________________________________________________________________
conv2d_350 (Conv2D)             (None, 13, 13, 192)  83136       activation_352[0][0]             
__________________________________________________________________________________________________
activation_353 (Activation)     (None, 13, 13, 192)  0           conv2d_349[0][0]                 
__________________________________________________________________________________________________
activation_354 (Activation)     (None, 13, 13, 192)  0           conv2d_350[0][0]                 
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 13, 13, 384)  0           activation_353[0][0]             
                                                                 activation_354[0][0]             
__________________________________________________________________________________________________
conv2d_351 (Conv2D)             (None, 13, 13, 64)   24640       concatenate_27[0][0]             
__________________________________________________________________________________________________
activation_355 (Activation)     (None, 13, 13, 64)   0           conv2d_351[0][0]                 
__________________________________________________________________________________________________
conv2d_352 (Conv2D)             (None, 13, 13, 256)  16640       activation_355[0][0]             
__________________________________________________________________________________________________
conv2d_353 (Conv2D)             (None, 13, 13, 256)  147712      activation_355[0][0]             
__________________________________________________________________________________________________
activation_356 (Activation)     (None, 13, 13, 256)  0           conv2d_352[0][0]                 
__________________________________________________________________________________________________
activation_357 (Activation)     (None, 13, 13, 256)  0           conv2d_353[0][0]                 
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 13, 13, 512)  0           activation_356[0][0]             
                                                                 activation_357[0][0]             
__________________________________________________________________________________________________
conv2d_354 (Conv2D)             (None, 13, 13, 64)   32832       concatenate_28[0][0]             
__________________________________________________________________________________________________
activation_358 (Activation)     (None, 13, 13, 64)   0           conv2d_354[0][0]                 
__________________________________________________________________________________________________
conv2d_355 (Conv2D)             (None, 13, 13, 256)  16640       activation_358[0][0]             
__________________________________________________________________________________________________
conv2d_356 (Conv2D)             (None, 13, 13, 256)  147712      activation_358[0][0]             
__________________________________________________________________________________________________
activation_359 (Activation)     (None, 13, 13, 256)  0           conv2d_355[0][0]                 
__________________________________________________________________________________________________
activation_360 (Activation)     (None, 13, 13, 256)  0           conv2d_356[0][0]                 
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 13, 13, 512)  0           activation_359[0][0]             
                                                                 activation_360[0][0]             
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 512)  0           concatenate_29[0][0]             
__________________________________________________________________________________________________
last_conv (Conv2D)              (None, 13, 13, 10)   5130        dropout_2[0][0]                  
__________________________________________________________________________________________________
activation_361 (Activation)     (None, 13, 13, 10)   0           last_conv[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d_2 (Glo (None, 10)           0           activation_361[0][0]             
__________________________________________________________________________________________________
activation_362 (Activation)     (None, 10)           0           global_average_pooling2d_2[0][0] 
==================================================================================================
Total params: 727,626
Trainable params: 727,626
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
Using Enhanced Data Generation
Found 9000 images belonging to 10 classes.
Found 2000 images belonging to 10 classes.
JSON Mapping for the model classes saved to  /content/drive/My Drive/imageprocessing/idenprof/json/model_class.json
Number of experiments (Epochs) :  25
Epoch 1/25
69/70 [============================>.] - ETA: 1s - loss: 2.3029 - acc: 0.0954Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00001: val_acc improved from -inf to 0.10052, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-001_acc-0.100521.h5
70/70 [==============================] - 151s 2s/step - loss: 2.3029 - acc: 0.0952 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 2/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.0964Epoch 1/25
15/70 [=====>........................] - ETA: 28s - loss: 2.3026 - acc: 0.1005
Epoch 00002: val_acc did not improve from 0.10052
70/70 [==============================] - 135s 2s/step - loss: 2.3026 - acc: 0.0960 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 3/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1011Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00003: val_acc did not improve from 0.10052
70/70 [==============================] - 133s 2s/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 4/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1014Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00004: val_acc did not improve from 0.10052
70/70 [==============================] - 133s 2s/step - loss: 2.3026 - acc: 0.1010 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 5/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1024Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00005: val_acc did not improve from 0.10052
70/70 [==============================] - 131s 2s/step - loss: 2.3026 - acc: 0.1021 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 6/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.0972Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00006: val_acc did not improve from 0.10052
70/70 [==============================] - 130s 2s/step - loss: 2.3026 - acc: 0.0977 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 7/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1019Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00007: val_acc did not improve from 0.10052
70/70 [==============================] - 132s 2s/step - loss: 2.3026 - acc: 0.1016 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 8/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.0992Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00008: val_acc did not improve from 0.10052
70/70 [==============================] - 130s 2s/step - loss: 2.3026 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 9/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.0971Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00009: val_acc did not improve from 0.10052
70/70 [==============================] - 131s 2s/step - loss: 2.3026 - acc: 0.0968 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 10/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.0979Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00010: val_acc did not improve from 0.10052
70/70 [==============================] - 130s 2s/step - loss: 2.3026 - acc: 0.0979 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 11/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1029Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00011: val_acc did not improve from 0.10052
70/70 [==============================] - 131s 2s/step - loss: 2.3026 - acc: 0.1027 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 12/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.0961Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3026 - acc: 0.1005
Epoch 00012: val_acc did not improve from 0.10052
70/70 [==============================] - 133s 2s/step - loss: 2.3026 - acc: 0.0957 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 13/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1011Epoch 1/25
15/70 [=====>........................] - ETA: 29s - loss: 2.3026 - acc: 0.1005
Epoch 00013: val_acc did not improve from 0.10052
70/70 [==============================] - 130s 2s/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 14/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1009Epoch 1/25
15/70 [=====>........................] - ETA: 29s - loss: 2.3026 - acc: 0.1005
Epoch 00014: val_acc did not improve from 0.10052
70/70 [==============================] - 131s 2s/step - loss: 2.3026 - acc: 0.1007 - val_loss: 2.3026 - val_acc: 0.1005
Epoch 15/25
69/70 [============================>.] - ETA: 1s - loss: 2.3025 - acc: 0.1016Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3015 - acc: 0.1615
Epoch 00015: val_acc improved from 0.10052 to 0.16146, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-015_acc-0.161458.h5
70/70 [==============================] - 131s 2s/step - loss: 2.3025 - acc: 0.1019 - val_loss: 2.3015 - val_acc: 0.1615
Epoch 16/25
69/70 [============================>.] - ETA: 1s - loss: 2.3019 - acc: 0.1068Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00016: val_acc did not improve from 0.16146
70/70 [==============================] - 133s 2s/step - loss: 2.3020 - acc: 0.1063 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 17/25
69/70 [============================>.] - ETA: 1s - loss: 2.3027 - acc: 0.0997Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00017: val_acc did not improve from 0.16146
70/70 [==============================] - 129s 2s/step - loss: 2.3027 - acc: 0.0999 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 18/25
69/70 [============================>.] - ETA: 1s - loss: 2.3028 - acc: 0.0977Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00018: val_acc did not improve from 0.16146
70/70 [==============================] - 131s 2s/step - loss: 2.3028 - acc: 0.0976 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 19/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1022Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00019: val_acc did not improve from 0.16146
70/70 [==============================] - 132s 2s/step - loss: 2.3026 - acc: 0.1020 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 20/25
69/70 [============================>.] - ETA: 1s - loss: 2.3028 - acc: 0.0990Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00020: val_acc did not improve from 0.16146
70/70 [==============================] - 129s 2s/step - loss: 2.3027 - acc: 0.0994 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 21/25
69/70 [============================>.] - ETA: 1s - loss: 2.3027 - acc: 0.0983Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00021: val_acc did not improve from 0.16146
70/70 [==============================] - 132s 2s/step - loss: 2.3027 - acc: 0.0982 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 22/25
69/70 [============================>.] - ETA: 1s - loss: 2.3025 - acc: 0.1040Epoch 1/25
15/70 [=====>........................] - ETA: 29s - loss: 2.3027 - acc: 0.1000
Epoch 00022: val_acc did not improve from 0.16146
70/70 [==============================] - 129s 2s/step - loss: 2.3025 - acc: 0.1045 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 23/25
69/70 [============================>.] - ETA: 1s - loss: 2.3028 - acc: 0.0963Epoch 1/25
15/70 [=====>........................] - ETA: 29s - loss: 2.3027 - acc: 0.1000
Epoch 00023: val_acc did not improve from 0.16146
70/70 [==============================] - 127s 2s/step - loss: 2.3028 - acc: 0.0963 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 24/25
69/70 [============================>.] - ETA: 1s - loss: 2.3026 - acc: 0.1021Epoch 1/25
15/70 [=====>........................] - ETA: 29s - loss: 2.3027 - acc: 0.1000
Epoch 00024: val_acc did not improve from 0.16146
70/70 [==============================] - 128s 2s/step - loss: 2.3026 - acc: 0.1017 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 25/25
69/70 [============================>.] - ETA: 1s - loss: 2.3027 - acc: 0.0988Epoch 1/25
15/70 [=====>........................] - ETA: 30s - loss: 2.3027 - acc: 0.1000
Epoch 00025: val_acc did not improve from 0.16146
70/70 [==============================] - 128s 2s/step - loss: 2.3027 - acc: 0.0986 - val_loss: 2.3027 - val_acc: 0.1000
SqueezeNet Model training completed!