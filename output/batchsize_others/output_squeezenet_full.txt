SqueezeNet Model training starting now!
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 111, 111, 64) 1792        input_3[0][0]                    
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 111, 111, 64) 0           conv2d_106[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_100[0][0]             
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 55, 55, 16)   1040        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 55, 55, 16)   0           conv2d_107[0][0]                 
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 55, 55, 64)   1088        activation_101[0][0]             
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 55, 55, 64)   9280        activation_101[0][0]             
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 55, 55, 64)   0           conv2d_108[0][0]                 
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 55, 55, 64)   0           conv2d_109[0][0]                 
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 55, 55, 128)  0           activation_102[0][0]             
                                                                 activation_103[0][0]             
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 55, 55, 16)   2064        concatenate[0][0]                
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 55, 55, 16)   0           conv2d_110[0][0]                 
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 55, 55, 64)   1088        activation_104[0][0]             
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 55, 55, 64)   9280        activation_104[0][0]             
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 55, 55, 64)   0           conv2d_111[0][0]                 
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 55, 55, 64)   0           conv2d_112[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 55, 55, 128)  0           activation_105[0][0]             
                                                                 activation_106[0][0]             
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 27, 27, 128)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 27, 27, 32)   4128        max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 27, 27, 32)   0           conv2d_113[0][0]                 
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 27, 27, 128)  4224        activation_107[0][0]             
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 27, 27, 128)  36992       activation_107[0][0]             
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 27, 27, 128)  0           conv2d_114[0][0]                 
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 27, 27, 128)  0           conv2d_115[0][0]                 
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 27, 256)  0           activation_108[0][0]             
                                                                 activation_109[0][0]             
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 27, 27, 32)   8224        concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 27, 27, 32)   0           conv2d_116[0][0]                 
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 27, 27, 128)  4224        activation_110[0][0]             
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 27, 27, 128)  36992       activation_110[0][0]             
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 27, 27, 128)  0           conv2d_117[0][0]                 
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 27, 27, 128)  0           conv2d_118[0][0]                 
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 27, 27, 256)  0           activation_111[0][0]             
                                                                 activation_112[0][0]             
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 256)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 13, 13, 48)   12336       max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 13, 13, 48)   0           conv2d_119[0][0]                 
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 13, 13, 192)  9408        activation_113[0][0]             
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 13, 13, 192)  83136       activation_113[0][0]             
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 13, 13, 192)  0           conv2d_120[0][0]                 
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 13, 13, 192)  0           conv2d_121[0][0]                 
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 13, 13, 384)  0           activation_114[0][0]             
                                                                 activation_115[0][0]             
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 13, 13, 48)   18480       concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 13, 13, 48)   0           conv2d_122[0][0]                 
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 13, 13, 192)  9408        activation_116[0][0]             
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 13, 13, 192)  83136       activation_116[0][0]             
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 13, 13, 192)  0           conv2d_123[0][0]                 
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 13, 13, 192)  0           conv2d_124[0][0]                 
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 13, 13, 384)  0           activation_117[0][0]             
                                                                 activation_118[0][0]             
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 13, 13, 64)   24640       concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 13, 13, 64)   0           conv2d_125[0][0]                 
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 13, 13, 256)  16640       activation_119[0][0]             
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 13, 13, 256)  147712      activation_119[0][0]             
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 13, 13, 256)  0           conv2d_126[0][0]                 
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 13, 13, 256)  0           conv2d_127[0][0]                 
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 13, 13, 512)  0           activation_120[0][0]             
                                                                 activation_121[0][0]             
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 13, 13, 64)   32832       concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 13, 13, 64)   0           conv2d_128[0][0]                 
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 13, 13, 256)  16640       activation_122[0][0]             
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 13, 13, 256)  147712      activation_122[0][0]             
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 13, 13, 256)  0           conv2d_129[0][0]                 
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 13, 13, 256)  0           conv2d_130[0][0]                 
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 13, 13, 512)  0           activation_123[0][0]             
                                                                 activation_124[0][0]             
__________________________________________________________________________________________________
dropout (Dropout)               (None, 13, 13, 512)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
last_conv (Conv2D)              (None, 13, 13, 10)   5130        dropout[0][0]                    
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 13, 13, 10)   0           last_conv[0][0]                  
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 10)           0           activation_125[0][0]             
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 10)           0           global_average_pooling2d[0][0]   
==================================================================================================
Total params: 727,626
Trainable params: 727,626
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
Using Enhanced Data Generation
Found 9000 images belonging to 10 classes.
Found 2000 images belonging to 10 classes.
JSON Mapping for the model classes saved to  /content/drive/My Drive/imageprocessing/idenprof/json/model_class.json
Number of experiments (Epochs) :  25
Epoch 1/25
280/281 [============================>.] - ETA: 0s - loss: 2.3028 - acc: 0.1018Epoch 1/25
 62/281 [=====>........................] - ETA: 28s - loss: 2.3026 - acc: 0.0998
Epoch 00001: val_acc improved from -inf to 0.09980, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-001_acc-0.099798.h5
281/281 [==============================] - 152s 542ms/step - loss: 2.3028 - acc: 0.1018 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 2/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0969Epoch 1/25
 62/281 [=====>........................] - ETA: 25s - loss: 2.3026 - acc: 0.0998
Epoch 00002: val_acc did not improve from 0.09980
281/281 [==============================] - 138s 491ms/step - loss: 2.3026 - acc: 0.0969 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 3/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1017Epoch 1/25
 62/281 [=====>........................] - ETA: 26s - loss: 2.3026 - acc: 0.0998
Epoch 00003: val_acc did not improve from 0.09980
281/281 [==============================] - 141s 501ms/step - loss: 2.3026 - acc: 0.1021 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 4/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1019Epoch 1/25
 62/281 [=====>........................] - ETA: 27s - loss: 2.3026 - acc: 0.0998
Epoch 00004: val_acc did not improve from 0.09980
281/281 [==============================] - 140s 499ms/step - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 5/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0979Epoch 1/25
 62/281 [=====>........................] - ETA: 27s - loss: 2.3026 - acc: 0.0998
Epoch 00005: val_acc did not improve from 0.09980
281/281 [==============================] - 140s 497ms/step - loss: 2.3026 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 6/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1053Epoch 1/25
 62/281 [=====>........................] - ETA: 28s - loss: 2.3026 - acc: 0.0998
Epoch 00006: val_acc did not improve from 0.09980
281/281 [==============================] - 140s 498ms/step - loss: 2.3026 - acc: 0.1056 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 7/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0949Epoch 1/25
 62/281 [=====>........................] - ETA: 28s - loss: 2.3026 - acc: 0.0998
Epoch 00007: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 488ms/step - loss: 2.3026 - acc: 0.0948 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 8/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0999Epoch 1/25
 62/281 [=====>........................] - ETA: 28s - loss: 2.3026 - acc: 0.0998
Epoch 00008: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 487ms/step - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 9/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1025Epoch 1/25
 62/281 [=====>........................] - ETA: 29s - loss: 2.3026 - acc: 0.0998
Epoch 00009: val_acc did not improve from 0.09980
281/281 [==============================] - 136s 482ms/step - loss: 2.3026 - acc: 0.1026 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 10/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0988Epoch 1/25
 62/281 [=====>........................] - ETA: 32s - loss: 2.3026 - acc: 0.0998
Epoch 00010: val_acc did not improve from 0.09980
281/281 [==============================] - 136s 484ms/step - loss: 2.3026 - acc: 0.0988 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 11/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1012Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00011: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 489ms/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 12/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0986Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00012: val_acc did not improve from 0.09980
281/281 [==============================] - 136s 485ms/step - loss: 2.3026 - acc: 0.0986 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 13/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1006Epoch 1/25
 62/281 [=====>........................] - ETA: 32s - loss: 2.3026 - acc: 0.0998
Epoch 00013: val_acc did not improve from 0.09980
281/281 [==============================] - 138s 489ms/step - loss: 2.3026 - acc: 0.1004 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 14/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0950Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00014: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 488ms/step - loss: 2.3026 - acc: 0.0950 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 15/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1005Epoch 1/25
 62/281 [=====>........................] - ETA: 32s - loss: 2.3026 - acc: 0.0998
Epoch 00015: val_acc did not improve from 0.09980
281/281 [==============================] - 139s 493ms/step - loss: 2.3026 - acc: 0.1005 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 16/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0978Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00016: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 487ms/step - loss: 2.3026 - acc: 0.0977 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 17/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0960Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00017: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 489ms/step - loss: 2.3026 - acc: 0.0961 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 18/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1036Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00018: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 488ms/step - loss: 2.3026 - acc: 0.1036 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 19/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1019Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00019: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 487ms/step - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 20/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.1077Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00020: val_acc did not improve from 0.09980
281/281 [==============================] - 138s 492ms/step - loss: 2.3026 - acc: 0.1076 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 21/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0970Epoch 1/25
 62/281 [=====>........................] - ETA: 32s - loss: 2.3026 - acc: 0.0998
Epoch 00021: val_acc did not improve from 0.09980
281/281 [==============================] - 137s 488ms/step - loss: 2.3026 - acc: 0.0970 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 22/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0996Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00022: val_acc did not improve from 0.09980
281/281 [==============================] - 138s 491ms/step - loss: 2.3026 - acc: 0.0996 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 23/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0975Epoch 1/25
 62/281 [=====>........................] - ETA: 32s - loss: 2.3026 - acc: 0.0998
Epoch 00023: val_acc did not improve from 0.09980
281/281 [==============================] - 138s 492ms/step - loss: 2.3026 - acc: 0.0973 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 24/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0977Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00024: val_acc did not improve from 0.09980
281/281 [==============================] - 139s 495ms/step - loss: 2.3026 - acc: 0.0975 - val_loss: 2.3026 - val_acc: 0.0998
Epoch 25/25
280/281 [============================>.] - ETA: 0s - loss: 2.3026 - acc: 0.0973Epoch 1/25
 62/281 [=====>........................] - ETA: 31s - loss: 2.3026 - acc: 0.0998
Epoch 00025: val_acc did not improve from 0.09980
281/281 [==============================] - 139s 494ms/step - loss: 2.3026 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.0998
SqueezeNet Model training completed!