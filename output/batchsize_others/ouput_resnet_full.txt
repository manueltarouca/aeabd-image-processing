ResNet Model training starting now!
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     
__________________________________________________________________________________________________
activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 55, 55, 64)   36928       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 55, 55, 64)   256         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 55, 55, 64)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 55, 55, 256)  1024        conv2d_1[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 55, 55, 256)  0           batch_normalization_4[0][0]      
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 55, 55, 64)   16448       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 55, 55, 64)   36928       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 55, 55, 256)  16640       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 55, 55, 256)  0           batch_normalization_7[0][0]      
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 55, 55, 64)   16448       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 55, 55, 64)   36928       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 55, 55, 256)  16640       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_10[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_10[0][0]     
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_14[0][0]     
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 14, 14, 256)  131328      activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 14, 14, 256)  590080      activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 14, 14, 1024) 263168      activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 14, 14, 1024) 525312      activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_27[0][0]     
                                                                 batch_normalization_24[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     
                                                                 activation_24[0][0]              
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     
                                                                 activation_27[0][0]              
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     
                                                                 activation_30[0][0]              
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     
                                                                 activation_33[0][0]              
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      activation_38[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     
                                                                 activation_36[0][0]              
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 7, 7, 512)    524800      activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359808     activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_41[0][0]              
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     activation_42[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     
                                                                 activation_42[0][0]              
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     
                                                                 activation_45[0][0]              
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     
__________________________________________________________________________________________________
global_avg_pooling (GlobalAvera (None, 2048)         0           activation_48[0][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 10)           20490       global_avg_pooling[0][0]         
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 10)           0           dense[0][0]                      
==================================================================================================
Total params: 23,608,202
Trainable params: 23,555,082
Non-trainable params: 53,120
__________________________________________________________________________________________________
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.
Using Enhanced Data Generation
Found 9000 images belonging to 10 classes.
Found 2000 images belonging to 10 classes.
JSON Mapping for the model classes saved to  /content/drive/My Drive/imageprocessing/idenprof/json/model_class.json
Number of experiments (Epochs) :  25
Epoch 1/25
280/281 [============================>.] - ETA: 0s - loss: 1.9134 - acc: 0.3782Epoch 1/25
 62/281 [=====>........................] - ETA: 59s - loss: 10.4665 - acc: 0.1416 
Epoch 00001: val_acc improved from -inf to 0.14163, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-001_acc-0.141633.h5
281/281 [==============================] - 315s 1s/step - loss: 1.9117 - acc: 0.3788 - val_loss: 10.4665 - val_acc: 0.1416
Epoch 2/25
280/281 [============================>.] - ETA: 0s - loss: 1.4733 - acc: 0.4875Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 2.1536 - acc: 0.3211
Epoch 00002: val_acc improved from 0.14163 to 0.32107, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-002_acc-0.321069.h5
281/281 [==============================] - 259s 921ms/step - loss: 1.4736 - acc: 0.4873 - val_loss: 2.1536 - val_acc: 0.3211
Epoch 3/25
280/281 [============================>.] - ETA: 0s - loss: 1.3475 - acc: 0.5365Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 2.2254 - acc: 0.3876
Epoch 00003: val_acc improved from 0.32107 to 0.38760, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-003_acc-0.387601.h5
281/281 [==============================] - 259s 922ms/step - loss: 1.3473 - acc: 0.5366 - val_loss: 2.2254 - val_acc: 0.3876
Epoch 4/25
280/281 [============================>.] - ETA: 0s - loss: 1.2399 - acc: 0.5752Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 1.8210 - acc: 0.4360
Epoch 00004: val_acc improved from 0.38760 to 0.43599, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-004_acc-0.435988.h5
281/281 [==============================] - 259s 923ms/step - loss: 1.2394 - acc: 0.5755 - val_loss: 1.8210 - val_acc: 0.4360
Epoch 5/25
280/281 [============================>.] - ETA: 0s - loss: 1.1711 - acc: 0.6034Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 4.0306 - acc: 0.3684
Epoch 00005: val_acc did not improve from 0.43599
281/281 [==============================] - 258s 920ms/step - loss: 1.1715 - acc: 0.6035 - val_loss: 4.0306 - val_acc: 0.3684
Epoch 6/25
280/281 [============================>.] - ETA: 0s - loss: 1.0897 - acc: 0.6211Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 1.8415 - acc: 0.4793
Epoch 00006: val_acc improved from 0.43599 to 0.47933, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-006_acc-0.479335.h5
281/281 [==============================] - 259s 922ms/step - loss: 1.0905 - acc: 0.6209 - val_loss: 1.8415 - val_acc: 0.4793
Epoch 7/25
280/281 [============================>.] - ETA: 0s - loss: 1.0235 - acc: 0.6493Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 1.8560 - acc: 0.4819
Epoch 00007: val_acc improved from 0.47933 to 0.48185, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-007_acc-0.481855.h5
281/281 [==============================] - 259s 921ms/step - loss: 1.0232 - acc: 0.6492 - val_loss: 1.8560 - val_acc: 0.4819
Epoch 8/25
280/281 [============================>.] - ETA: 0s - loss: 1.0127 - acc: 0.6542Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 2.4441 - acc: 0.4128
Epoch 00008: val_acc did not improve from 0.48185
281/281 [==============================] - 258s 916ms/step - loss: 1.0119 - acc: 0.6548 - val_loss: 2.4441 - val_acc: 0.4128
Epoch 9/25
280/281 [============================>.] - ETA: 0s - loss: 0.9948 - acc: 0.6642Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 51.7537 - acc: 0.1759
Epoch 00009: val_acc did not improve from 0.48185
281/281 [==============================] - 258s 918ms/step - loss: 0.9942 - acc: 0.6645 - val_loss: 51.7537 - val_acc: 0.1759
Epoch 10/25
280/281 [============================>.] - ETA: 0s - loss: 0.9618 - acc: 0.6710Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 4.0056 - acc: 0.3266
Epoch 00010: val_acc did not improve from 0.48185
281/281 [==============================] - 258s 918ms/step - loss: 0.9610 - acc: 0.6709 - val_loss: 4.0056 - val_acc: 0.3266
Epoch 11/25
280/281 [============================>.] - ETA: 0s - loss: 0.8525 - acc: 0.7076Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 1.1498 - acc: 0.6195
Epoch 00011: val_acc improved from 0.48185 to 0.61946, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-011_acc-0.619456.h5
281/281 [==============================] - 259s 921ms/step - loss: 0.8517 - acc: 0.7079 - val_loss: 1.1498 - val_acc: 0.6195
Epoch 12/25
280/281 [============================>.] - ETA: 0s - loss: 0.6833 - acc: 0.7625Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.7258 - acc: 0.7611
Epoch 00012: val_acc improved from 0.61946 to 0.76109, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-012_acc-0.761089.h5
281/281 [==============================] - 258s 920ms/step - loss: 0.6827 - acc: 0.7628 - val_loss: 0.7258 - val_acc: 0.7611
Epoch 13/25
280/281 [============================>.] - ETA: 0s - loss: 0.6207 - acc: 0.7844Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.7211 - acc: 0.7722
Epoch 00013: val_acc improved from 0.76109 to 0.77218, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-013_acc-0.772177.h5
281/281 [==============================] - 259s 920ms/step - loss: 0.6202 - acc: 0.7843 - val_loss: 0.7211 - val_acc: 0.7722
Epoch 14/25
280/281 [============================>.] - ETA: 0s - loss: 0.5830 - acc: 0.8005Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.7541 - acc: 0.7520
Epoch 00014: val_acc did not improve from 0.77218
281/281 [==============================] - 258s 916ms/step - loss: 0.5825 - acc: 0.8005 - val_loss: 0.7541 - val_acc: 0.7520
Epoch 15/25
280/281 [============================>.] - ETA: 0s - loss: 0.5618 - acc: 0.8072Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.7274 - acc: 0.7616
Epoch 00015: val_acc did not improve from 0.77218
281/281 [==============================] - 258s 918ms/step - loss: 0.5618 - acc: 0.8071 - val_loss: 0.7274 - val_acc: 0.7616
Epoch 16/25
280/281 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.8165Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.7694 - acc: 0.7470
Epoch 00016: val_acc did not improve from 0.77218
281/281 [==============================] - 258s 919ms/step - loss: 0.5390 - acc: 0.8169 - val_loss: 0.7694 - val_acc: 0.7470
Epoch 17/25
280/281 [============================>.] - ETA: 0s - loss: 0.5103 - acc: 0.8214Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.6706 - acc: 0.7833
Epoch 00017: val_acc improved from 0.77218 to 0.78327, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-017_acc-0.783266.h5
281/281 [==============================] - 258s 919ms/step - loss: 0.5106 - acc: 0.8212 - val_loss: 0.6706 - val_acc: 0.7833
Epoch 18/25
280/281 [============================>.] - ETA: 0s - loss: 0.5008 - acc: 0.8270Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.6765 - acc: 0.7853
Epoch 00018: val_acc improved from 0.78327 to 0.78528, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-018_acc-0.785282.h5
281/281 [==============================] - 259s 921ms/step - loss: 0.5001 - acc: 0.8274 - val_loss: 0.6765 - val_acc: 0.7853
Epoch 19/25
280/281 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8321Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.6790 - acc: 0.7807
Epoch 00019: val_acc did not improve from 0.78528
281/281 [==============================] - 258s 918ms/step - loss: 0.4867 - acc: 0.8320 - val_loss: 0.6790 - val_acc: 0.7807
Epoch 20/25
280/281 [============================>.] - ETA: 0s - loss: 0.4827 - acc: 0.8297Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.6680 - acc: 0.7828
Epoch 00020: val_acc did not improve from 0.78528
281/281 [==============================] - 258s 917ms/step - loss: 0.4836 - acc: 0.8294 - val_loss: 0.6680 - val_acc: 0.7828
Epoch 21/25
280/281 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8301Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.6726 - acc: 0.7843
Epoch 00021: val_acc did not improve from 0.78528
281/281 [==============================] - 258s 917ms/step - loss: 0.4930 - acc: 0.8305 - val_loss: 0.6726 - val_acc: 0.7843
Epoch 22/25
280/281 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.8329Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.6721 - acc: 0.7858
Epoch 00022: val_acc improved from 0.78528 to 0.78579, saving model to /content/drive/My Drive/imageprocessing/idenprof/models/model_ex-022_acc-0.785786.h5
281/281 [==============================] - 259s 920ms/step - loss: 0.4786 - acc: 0.8330 - val_loss: 0.6721 - val_acc: 0.7858
Epoch 23/25
280/281 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8377Epoch 1/25
 62/281 [=====>........................] - ETA: 53s - loss: 0.6736 - acc: 0.7848
Epoch 00023: val_acc did not improve from 0.78579
281/281 [==============================] - 258s 917ms/step - loss: 0.4716 - acc: 0.8375 - val_loss: 0.6736 - val_acc: 0.7848
Epoch 24/25
280/281 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.8347Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.6734 - acc: 0.7828
Epoch 00024: val_acc did not improve from 0.78579
281/281 [==============================] - 258s 918ms/step - loss: 0.4779 - acc: 0.8349 - val_loss: 0.6734 - val_acc: 0.7828
Epoch 25/25
280/281 [============================>.] - ETA: 0s - loss: 0.4732 - acc: 0.8359Epoch 1/25
 62/281 [=====>........................] - ETA: 52s - loss: 0.6736 - acc: 0.7853
Epoch 00025: val_acc did not improve from 0.78579
281/281 [==============================] - 258s 918ms/step - loss: 0.4739 - acc: 0.8357 - val_loss: 0.6736 - val_acc: 0.7853
ResNet Model training completed!